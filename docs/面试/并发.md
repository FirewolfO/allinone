[toc]

# 死锁

## 死锁原因

- 互斥条件：一个资源每次只能被一个进程使用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
- 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系



## 避免死锁

- 避免一个线程同时获取多个锁
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
- 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。



# JMM

1. 数据是从主存拷贝，修改之后写会主存（屏蔽了不同硬件和操作系统内存的访问差异，这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行）。
2. 原子性：Java通过read、load、assign、use、store、write来保证原子性操作
3. 可见性：Java保证可见性通过volatile、synchronized、final来实现。
4. 有序性：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证
5. happen-before规则
   - 单线程每个操作，happen-before于该线程中任意后续操作
   - volatile写happen-before与后续对这个变量的读
   - synchronized解锁happen-before后续对这个锁的加锁
   - final变量的写happen-before于final域对象的读，happen-before后续对final变量的读
   - 传递性规则，A先于B，B先于C，那么A一定先于C发生





# Java并发机制的底层实现原理

Java中所使用的并发机制依赖于JVM的实现和CPU的指令。

这主要由以下几部分组成：

- cas
- volitale
- 锁

# Volitale

## 作用

- 禁止指令重排序 
- 让写操作对其他线程立马可见



## 底层实现

### 可见性

如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，接下来，通过以下两条规则实现volitale的可见性

1. **Lock前缀指令会引起处理器缓存回写到内存**
   - 锁总线（如Intel486和Pentium处理器）：在多处理器环境中，在总线锁定期间，处理器可以独占任何共享内存，开销比较大
   - 锁缓存（大部分处理器）：如果访问的内存区域已经缓存在处理器内部，会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。
2. **一个处理器的缓存回写到内存会导致其他处理器的缓存无效**
   - 通过缓存一致性协议MESI（Modify修改、Exclusive独占、Shared共享、Invalid无效）去维护内部缓存和其他处理器缓存的一致性；
   - 处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致；如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充

### 禁止指令重排序

通过插入内存屏障指令来完成：StoreStore、StoreLoad、LoadLoad、LoadStore



## 为什么会指令重排序

CPU计算的时候要访问值，如果常常利用到寄存器中已有的值就不用去内存读取了，为此，希望能把对一个变量的操作放在一起

重排序类型：

- 编译器优化重排序
- CPU重排序
- 内存重排序



# CAS

## 存在问题

- ABA：可以使用版本号解决。 JDK1.5开始，在atomic包增加了一个AtomicStampedReference来解决。AtomicMarkableReference 使用boolean mark来标记reference是否被修改过

- 循环时间长开销大：因为CPU空耗。如果JVM可以支持处理器提供的pause指令，那么会提高效率

- 只能保证一个共享变量的原子操作。可以通过把多个共享变量结合成一个共享变量解决。JDK1.5开始提供的AtomicReference可以保证引用变量的原子性；

  

# Synchronized

## 使用方式

Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：

- 普通同步方法，锁是当前实例对象
- 静态同步方法，锁是当前类的class对象
- 同步方法块，锁是括号里面的对象

## 编译器层面实现

- 同步代码块是使用monitorenter和monitorexit指令实现的

- 同步方法依靠的是方法修饰符上的ACC_SYNCHRONIZED实现

## 底层实现

对象监视器Monitor，通过CAS改变其MarkDown的状态变化来完成锁状态的变化，在升级成重量级锁的时候，是通过总线锁或者缓存锁实现；

Monitor是基于C++实现的，由ObjectMonitor实现的，ObjectMonitor中有几个关键属性：

- _owner：指向持有ObjectMonitor对象的线程
- _WaitSet：存放处于wait状态的线程队列
- _EntryList：存放处于等待锁block状态的线程队列
- recursions：锁的重入次数
- _count：用来记录该线程获取锁的次数_
- cxq：多线程竞争锁进入时的单向链表



## 锁升级过程

- 偏向锁：当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。
  - 偏向锁撤销：使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点。首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
- 轻量级锁：创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
- 重量级锁：因为自旋会消耗CPU，为了避免无用的自旋，升级为重量级锁



## Synchronized 和 CAS区别

- CAS：乐观锁的一种实现方式，是一个轻量级锁，可能有ABA和循环过多开销过大的问题，JDK旧版本只能操作单个变量
- Synchronized：悲观锁，必须先获取锁，然后再操作。





# Lock

AQS：CAS + volitale变量



# Synchronized VS Lock

| 对比项   | Synchronized                                                 | Lock                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 所在层次 | Java关键字，JVM层面                                          | 是一个类                                                     |
| 锁释放   | 1. 获取锁的线程执行完同步代码，释放锁；<br />2. <font color=red>**线程执行发生异常，JVM会让线程释放锁**</font> | 必须手动释放锁（一般放在finally），不然容易造成线程死锁      |
| 锁的获取 | A线程获取锁，B线程等待，那么如果A阻塞，B会一直等             | 可以通过尝试获得锁，不用一直等待；                           |
| 锁状态   | 无法判断                                                     | 可以判断 ： tryLock方法                                      |
| 锁类型   | 可重入、不可中断、非公平                                     | 可重入、可中断、支持公平锁和非公平锁                         |
| 性能     | 少量同步                                                     | 1. 大量同步<br />2. 可以提高多个线程进行读操作的效率（如readwritelock实现读写分离） |
| 调度机制 | Object对象的wait、notify、notifyAll                          | Condition的await、singnal、singnalAll                        |



# 可重入锁

- RetrantLock 和 Synchronized都是可重入锁可以多次获取到锁的，每次获取锁，加锁的标记数加+1，解锁的时候-1，加锁和解锁是配对的
- 采用AQS来实现锁



# 锁优化策略

- 锁消除：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除
- 自适应自旋：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。
- 错粗化：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。
- 锁升级策略



# 并发工具包

JDK1.5k开始，提供了并发工具包。`java.util.concurrent.*`

## 整体结构

![image-20220407095928969](https://gitee.com/firewolf/allinone/raw/master/images/image-20220407095928969.png)

## AQS

AQS内部维护一个state状态位，尝试加锁的时候通过CAS(CompareAndSwap)修改值，如果成功设置为1，并且把当前线程ID赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为0，同时当前线程ID置为空



## CountDownLanch 、CycleBarrier、Semaphore





# 线程

## 线程间通讯方式

- 共享全局变量
- 消息机制
- 管道



## HASH算法

Hash 算法有 MD5 和 SHA 系列



## 共享

数据清洗

## 线程状态

### java线程状态

- New（新创建）
- Runnable（可运行的）
- Blocked（阻塞的）
- Waiting（等待）
- Timed Waiting（计时等待）
- Terminated（被终止）



### 操作系统线程状态

- 初始态
- 可运行
- 运行态
- 阻塞态
- 终止态



## 创建线程的方式

1. 继承Thread
2. 实现Runnable接口
3. 实现Callable接口
4. 线程池



## Runnable 和 Callable区别

1. Runnable提供run方法，无法通过[throws](https://so.csdn.net/so/search?q=throws&spm=1001.2101.3001.7020)抛出异常，所有CheckedException必须在run方法内部处理。Callable提供call方法，直接抛出Exception异常。
2. Runnable的run方法无返回值，Callable的call方法提供返回值用来表示任务运行的结果
3. Runnable可以作为Thread构造器的参数，通过开启新的线程来执行，也可以通过线程池来执行。而Callable只能通过线程池执行。



## 线程池

### 种类

- newCachedThreadPool创建一个可缓存线程池程，队列是SynchronousQueue
- newFixedThreadPool 创建一个定长线程池，队列是LinkedBlockingQueue
- newScheduledThreadPool 创建一个周期性执行任务的线程池，队列是DelayQueue
- newSingleThreadExecutor 创建一个单线程化的线程池，队列是LinkedBlockingQueue

### 核心参数

- corePoolSize：核心线程数
- maxPoolSize：最大线程数
- keepAlivetime：线程空闲时间
- unit：线程等待时间单位
- rejectedExecutionHandler：任务拒绝处理器
  - AbortPolicy ：丢弃任务，抛出异常
  - CallerRunsPolicy：执行任务
  - DiscardPolicy：忽略
  - DiscardOldestPolicy：从队列中踢出最先进入队列
- threadFactory：线程工厂
- blockingQueue：阻塞队列

- 线程个数设置 
  - 最佳线程数 = Ncpu * Ucpu * (1 + W/C)
    - Ncpu：CPU核数，如 12
    - Ucpu：CPU利用率，如0.9
    - W/C：等待时间/计算时间，如：50（sleep时间） / 50 (循环50_000_000耗时)   = 1



# ThreadLocal

## 怎么保证线程安全的

多个线程访问同一个共享变量时，如果不做同步控制，往往会出现「数据不一致」的问题，通常会使用synchronized关键字加锁来解决，ThreadLocal则换了一个思路（空间换时间）。

ThreadLocal本身并不存储值，它依赖于Thread类中的ThreadLocalMap，当调用set(T value)时，ThreadLocal将自身作为Key，值作为Value存储到Thread类中的ThreadLocalMap中，这就相当于所有线程读写的都是自身的一个私有副本，线程之间的数据是隔离的，互不影响，也就不存在线程安全问题了。

![image-20220326150916828](https://gitee.com/firewolf/allinone/raw/master/images/image-20220326150916828.png)



## 内存泄漏问题

ThreadLocal的原理是操作Thread内部的一个ThreadLocalMap，这个Map的Entry继承了WeakReference,设值完成后map(WeakReference,value)这样的数据结构。java中的弱引用在内存不足的时候会被回收掉，回收之后变成(null,value)的形式，key被收回掉了。

如果线程执行完之后销毁，value也会被回收,这样也没问题。**<font color=red>但如果是在线程池中，线程执行完后不被回收，而是返回线程池中</font>**，此时ThreadLocal对象已经被销毁，一旦没有引用指向了ThreadLocal，那么Entry只持有弱引用的key就会自动在下一次YGC时被回收，而此时持有强引用的Entry对象并不会被回收。Thread有个强引用指向ThreadLocalMap,ThreadLocalMap有强引用指向Entry,导致value无法被回收，一直存在内存中。

在执行了ThreadLocal.set()方法之后一定要**<font color=red>记得使用ThreadLocal.remove(),将不要的数据移除掉</font>**，避免内存泄漏。

> ThreadLocal在以下几种情况会自发的清理掉key为null的Entry
>
> - 调用set()方法时，采样清理、全量清理，扩容时还会继续检查。
> - 调用get()方法，没有直接命中，向后环形查找时。
> - 调用remove()时，除了清理当前Entry，还会向后继续清理



# Java阻塞队列

一共有7个

- ArrayBlockingQueue：是一个用数组实现的有界阻塞队列。

  ```java
  final Object[] items;
  int takeIndex;
  int putIndex;
  int count;
  final ReentrantLock lock;
  private final Condition notEmpty;
  private final Condition notFull;
  ```

- LinkedBlockingQueue：是一个用链表实现的有界阻塞队列。

  ```java
  private final int capacity;
  private final AtomicInteger count = new AtomicInteger();
  transient Node<E> head;
  private transient Node<E> last;
  private final ReentrantLock takeLock = new ReentrantLock();
  private final Condition notEmpty = takeLock.newCondition();
  private final ReentrantLock putLock = new ReentrantLock();
  private final Condition notFull = putLock.newCondition();
  ```

- PriorityBlockingQueue：是一个支持优先级的无界阻塞队列。

  ```java
  private static final int DEFAULT_INITIAL_CAPACITY = 11;
  private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
  private transient Object[] queue;
  private transient int size;
  private transient Comparator<? super E> comparator;
  private final ReentrantLock lock;
  private final Condition notEmpty;
  private transient volatile int allocationSpinLock;
  private PriorityQueue<E> q;
  ```

- DelayQueue：是一个支持延时获取元素的无界阻塞队列。

  ```java
  private final PriorityQueue<E> q = new PriorityQueue<E>();
  private Thread leader = null;
  private final Condition available = lock.newCondition();
  ```

- LinkedBlockingDeque：是一个由链表结构组成的双向阻塞队列（Node有双向指针）

  ```java
  transient Node<E> first;
  transient Node<E> last;
  private transient int count;
  private final int capacity;
  final ReentrantLock lock = new ReentrantLock();
  private final Condition notEmpty = lock.newCondition();
  private final Condition notFull = lock.newCondition();
  ```

- SynchronousQueue：是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。

- LinkedTransferQueue：是一个由链表结构组成的无界阻塞TransferQueue队列。
